{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34125a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\helen\\anaconda3\\lib\\site-packages (4.9.9)\n",
      "Requirement already satisfied: absl-py in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.1.9)\n",
      "Requirement already satisfied: etils>=1.9.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (1.12.2)\n",
      "Requirement already satisfied: immutabledict in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Requirement already satisfied: promise in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.25.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (16.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Requirement already satisfied: simple_parsing in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.17.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.66.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Requirement already satisfied: einops in c:\\users\\helen\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\helen\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2024.6.1)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\helen\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\helen\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\helen\\anaconda3\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.1.31)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from dm-tree->tensorflow_datasets) (23.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\helen\\anaconda3\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from simple_parsing->tensorflow_datasets) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets) (1.70.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\helen\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\helen\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\helen\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: tensorflow.keras in c:\\users\\helen\\anaconda3\\lib\\site-packages (0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow_datasets\n",
    "! pip install tensorflow \n",
    "! pip install tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a190cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef749be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No GPU detected. Using CPU only.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# List physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"🚀 GPU(s) detected!\")\n",
    "    for gpu in gpus:\n",
    "        print(f\" - {gpu}\")\n",
    "    print(\"TensorFlow will use the GPU by default when available.\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected. Using CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd1e0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KMNIST from tensorflow_datasets\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kmnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9437e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function: flatten images and one-hot encode labels\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0         # Normalize to [0,1]\n",
    "    image = tf.reshape(image, [-1])                    # Flatten to 784\n",
    "    label = tf.one_hot(label, depth=10)                # One-hot encode\n",
    "    return image, label\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "ds_train = ds_train.map(preprocess).shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a357282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display one sample image from KMNIST (reshaped for visualization)\n",
    "\n",
    "for image, label in ds_train.take(1):\n",
    "    img = tf.reshape(image[0], (28, 28))  # Take the first image in the batch and reshape\n",
    "    plt.imshow(img.numpy(), cmap='gray')\n",
    "    plt.title(f\"Label: {np.argmax(label[0].numpy())}\")  # Show the class index\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87107c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\helen\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.7217 - loss: 0.8738 - val_accuracy: 0.1978 - val_loss: 2.2308 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8238 - loss: 0.5651 - val_accuracy: 0.5418 - val_loss: 1.8421 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8471 - loss: 0.4934 - val_accuracy: 0.8224 - val_loss: 0.8436 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 13s - 72ms/step - accuracy: 0.8556 - loss: 0.4634 - val_accuracy: 0.8855 - val_loss: 0.4011 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8614 - loss: 0.4462 - val_accuracy: 0.8916 - val_loss: 0.3574 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8626 - loss: 0.4411 - val_accuracy: 0.8943 - val_loss: 0.3468 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8656 - loss: 0.4348 - val_accuracy: 0.8940 - val_loss: 0.3457 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 13s - 72ms/step - accuracy: 0.8642 - loss: 0.4362 - val_accuracy: 0.8938 - val_loss: 0.3451 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8651 - loss: 0.4350 - val_accuracy: 0.8942 - val_loss: 0.3449 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8652 - loss: 0.4341 - val_accuracy: 0.8942 - val_loss: 0.3448 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 2/5\n",
      "Epoch 1/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.7219 - loss: 0.8904 - val_accuracy: 0.2024 - val_loss: 2.2238 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 13s - 71ms/step - accuracy: 0.8207 - loss: 0.5744 - val_accuracy: 0.5215 - val_loss: 1.7724 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8433 - loss: 0.5057 - val_accuracy: 0.8438 - val_loss: 0.8160 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8527 - loss: 0.4727 - val_accuracy: 0.8916 - val_loss: 0.3845 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8597 - loss: 0.4561 - val_accuracy: 0.8950 - val_loss: 0.3401 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 13s - 71ms/step - accuracy: 0.8615 - loss: 0.4471 - val_accuracy: 0.8973 - val_loss: 0.3324 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8620 - loss: 0.4456 - val_accuracy: 0.8974 - val_loss: 0.3316 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 13s - 71ms/step - accuracy: 0.8627 - loss: 0.4399 - val_accuracy: 0.8975 - val_loss: 0.3304 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 13s - 71ms/step - accuracy: 0.8636 - loss: 0.4417 - val_accuracy: 0.8978 - val_loss: 0.3301 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 13s - 71ms/step - accuracy: 0.8627 - loss: 0.4428 - val_accuracy: 0.8982 - val_loss: 0.3301 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 3/5\n",
      "Epoch 1/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.7167 - loss: 0.8878 - val_accuracy: 0.3907 - val_loss: 2.2259 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 20s - 109ms/step - accuracy: 0.8207 - loss: 0.5756 - val_accuracy: 0.5524 - val_loss: 1.8078 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8441 - loss: 0.5053 - val_accuracy: 0.8588 - val_loss: 0.7904 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8539 - loss: 0.4734 - val_accuracy: 0.8910 - val_loss: 0.3928 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8600 - loss: 0.4523 - val_accuracy: 0.8967 - val_loss: 0.3396 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8617 - loss: 0.4468 - val_accuracy: 0.8987 - val_loss: 0.3308 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 20s - 106ms/step - accuracy: 0.8629 - loss: 0.4422 - val_accuracy: 0.8997 - val_loss: 0.3296 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8615 - loss: 0.4417 - val_accuracy: 0.8996 - val_loss: 0.3286 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8651 - loss: 0.4388 - val_accuracy: 0.8994 - val_loss: 0.3285 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8649 - loss: 0.4388 - val_accuracy: 0.8997 - val_loss: 0.3283 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 4/5\n",
      "Epoch 1/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.7154 - loss: 0.9001 - val_accuracy: 0.2038 - val_loss: 2.2326 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8236 - loss: 0.5683 - val_accuracy: 0.6641 - val_loss: 1.7694 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8457 - loss: 0.4999 - val_accuracy: 0.8783 - val_loss: 0.7680 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8550 - loss: 0.4646 - val_accuracy: 0.9005 - val_loss: 0.3653 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8641 - loss: 0.4424 - val_accuracy: 0.9020 - val_loss: 0.3250 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 14s - 76ms/step - accuracy: 0.8647 - loss: 0.4369 - val_accuracy: 0.9048 - val_loss: 0.3135 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8665 - loss: 0.4312 - val_accuracy: 0.9059 - val_loss: 0.3119 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8654 - loss: 0.4347 - val_accuracy: 0.9053 - val_loss: 0.3111 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8652 - loss: 0.4320 - val_accuracy: 0.9054 - val_loss: 0.3109 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8661 - loss: 0.4316 - val_accuracy: 0.9053 - val_loss: 0.3108 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 5/5\n",
      "Epoch 1/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.7134 - loss: 0.8984 - val_accuracy: 0.2753 - val_loss: 2.2307 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8209 - loss: 0.5802 - val_accuracy: 0.6326 - val_loss: 1.7952 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8417 - loss: 0.5109 - val_accuracy: 0.8507 - val_loss: 0.8152 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8528 - loss: 0.4781 - val_accuracy: 0.8878 - val_loss: 0.3915 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 14s - 73ms/step - accuracy: 0.8542 - loss: 0.4657 - val_accuracy: 0.8969 - val_loss: 0.3421 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 13s - 70ms/step - accuracy: 0.8585 - loss: 0.4588 - val_accuracy: 0.8967 - val_loss: 0.3356 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8607 - loss: 0.4518 - val_accuracy: 0.8969 - val_loss: 0.3332 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 14s - 72ms/step - accuracy: 0.8604 - loss: 0.4479 - val_accuracy: 0.8974 - val_loss: 0.3322 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 14s - 74ms/step - accuracy: 0.8597 - loss: 0.4533 - val_accuracy: 0.8981 - val_loss: 0.3319 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 14s - 75ms/step - accuracy: 0.8592 - loss: 0.4515 - val_accuracy: 0.8976 - val_loss: 0.3318 - learning_rate: 5.2495e-07\n",
      "   Fold  Accuracy      Loss  Training Time (s)\n",
      "0     1  0.894167  0.344824         138.210299\n",
      "1     2  0.898167  0.330082         138.012985\n",
      "2     3  0.899750  0.328267         150.460855\n",
      "3     4  0.905333  0.310796         141.029601\n",
      "4     5  0.897583  0.331819         138.159028\n"
     ]
    }
   ],
   "source": [
    "# Prepare full dataset as numpy arrays for cross-validation\n",
    "images = []\n",
    "labels = []\n",
    "results = []\n",
    "\n",
    "for image, label in tfds.as_numpy(ds_train.unbatch()):\n",
    "    images.append(image.flatten() / 255.0)\n",
    "    labels.append(label) \n",
    "    \n",
    "X = np.array(images, dtype=np.float32)\n",
    "y = np.stack(labels).astype(np.float32)\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    return lr / np.sqrt(epoch + 1)\n",
    "\n",
    "lr_callback = LearningRateScheduler(scheduler)\n",
    "\n",
    "# K-Fold Cross-Validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(f\"🔁 Fold {fold+1}/5\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(784,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Optimizer setup\n",
    "    optimizer = Adam(\n",
    "        learning_rate=1e-3,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "        )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(\n",
    "        X[train_index], y[train_index],\n",
    "        validation_data=(X[val_index], y[val_index]),\n",
    "        epochs=10,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[lr_callback],\n",
    "        verbose=2\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X[val_index], y[val_index], verbose=0)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Fold': fold + 1,\n",
    "        'Accuracy': val_accuracy,\n",
    "        'Loss': val_loss,\n",
    "        'Training Time (s)': elapsed_time\n",
    "    })\n",
    "\n",
    "# Create and display table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cf5dc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\helen\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\helen\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Fold 1/5\n",
      "Epoch 1/10\n",
      "188/188 - 15s - 81ms/step - accuracy: 0.7184 - loss: 0.8859 - val_accuracy: 0.2137 - val_loss: 2.2083 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 15s - 81ms/step - accuracy: 0.8223 - loss: 0.5721 - val_accuracy: 0.7477 - val_loss: 1.7060 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 15s - 81ms/step - accuracy: 0.8439 - loss: 0.5076 - val_accuracy: 0.8578 - val_loss: 0.7607 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8549 - loss: 0.4674 - val_accuracy: 0.8819 - val_loss: 0.4119 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8598 - loss: 0.4527 - val_accuracy: 0.8873 - val_loss: 0.3678 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8633 - loss: 0.4450 - val_accuracy: 0.8894 - val_loss: 0.3607 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8632 - loss: 0.4383 - val_accuracy: 0.8899 - val_loss: 0.3579 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8634 - loss: 0.4398 - val_accuracy: 0.8902 - val_loss: 0.3570 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8630 - loss: 0.4400 - val_accuracy: 0.8902 - val_loss: 0.3566 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8644 - loss: 0.4392 - val_accuracy: 0.8905 - val_loss: 0.3565 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 2/5\n",
      "Epoch 1/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.7339 - loss: 0.8480 - val_accuracy: 0.2939 - val_loss: 2.2064 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8331 - loss: 0.5428 - val_accuracy: 0.7908 - val_loss: 1.7043 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8512 - loss: 0.4760 - val_accuracy: 0.8737 - val_loss: 0.7127 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8635 - loss: 0.4426 - val_accuracy: 0.8962 - val_loss: 0.3641 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8690 - loss: 0.4237 - val_accuracy: 0.9006 - val_loss: 0.3244 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8709 - loss: 0.4130 - val_accuracy: 0.9033 - val_loss: 0.3157 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 16s - 87ms/step - accuracy: 0.8736 - loss: 0.4089 - val_accuracy: 0.9017 - val_loss: 0.3140 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 15s - 81ms/step - accuracy: 0.8731 - loss: 0.4061 - val_accuracy: 0.9024 - val_loss: 0.3133 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 15s - 81ms/step - accuracy: 0.8736 - loss: 0.4110 - val_accuracy: 0.9023 - val_loss: 0.3131 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8752 - loss: 0.4065 - val_accuracy: 0.9022 - val_loss: 0.3131 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 3/5\n",
      "Epoch 1/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.7109 - loss: 0.9036 - val_accuracy: 0.1050 - val_loss: 2.2273 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 14s - 77ms/step - accuracy: 0.8182 - loss: 0.5836 - val_accuracy: 0.6691 - val_loss: 1.7718 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 15s - 81ms/step - accuracy: 0.8410 - loss: 0.5135 - val_accuracy: 0.8480 - val_loss: 0.7848 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 15s - 77ms/step - accuracy: 0.8507 - loss: 0.4840 - val_accuracy: 0.8862 - val_loss: 0.4055 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 15s - 77ms/step - accuracy: 0.8563 - loss: 0.4671 - val_accuracy: 0.8955 - val_loss: 0.3531 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 14s - 77ms/step - accuracy: 0.8605 - loss: 0.4538 - val_accuracy: 0.8966 - val_loss: 0.3423 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8580 - loss: 0.4549 - val_accuracy: 0.8973 - val_loss: 0.3401 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8594 - loss: 0.4576 - val_accuracy: 0.8970 - val_loss: 0.3395 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8594 - loss: 0.4563 - val_accuracy: 0.8969 - val_loss: 0.3393 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8600 - loss: 0.4516 - val_accuracy: 0.8971 - val_loss: 0.3393 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 4/5\n",
      "Epoch 1/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.7057 - loss: 0.9213 - val_accuracy: 0.3433 - val_loss: 2.2294 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 15s - 80ms/step - accuracy: 0.8145 - loss: 0.5938 - val_accuracy: 0.5534 - val_loss: 1.8193 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 14s - 77ms/step - accuracy: 0.8336 - loss: 0.5296 - val_accuracy: 0.8497 - val_loss: 0.8039 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8463 - loss: 0.4955 - val_accuracy: 0.8894 - val_loss: 0.3991 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 21s - 109ms/step - accuracy: 0.8519 - loss: 0.4770 - val_accuracy: 0.8964 - val_loss: 0.3439 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8544 - loss: 0.4695 - val_accuracy: 0.8979 - val_loss: 0.3356 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 15s - 77ms/step - accuracy: 0.8552 - loss: 0.4665 - val_accuracy: 0.8989 - val_loss: 0.3333 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 15s - 77ms/step - accuracy: 0.8543 - loss: 0.4652 - val_accuracy: 0.8985 - val_loss: 0.3331 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 15s - 77ms/step - accuracy: 0.8570 - loss: 0.4671 - val_accuracy: 0.8993 - val_loss: 0.3330 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 15s - 77ms/step - accuracy: 0.8545 - loss: 0.4691 - val_accuracy: 0.8992 - val_loss: 0.3329 - learning_rate: 5.2495e-07\n",
      "🔁 Fold 5/5\n",
      "Epoch 1/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.7176 - loss: 0.8799 - val_accuracy: 0.2977 - val_loss: 2.2065 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "188/188 - 20s - 109ms/step - accuracy: 0.8270 - loss: 0.5610 - val_accuracy: 0.7829 - val_loss: 1.7286 - learning_rate: 7.0711e-04\n",
      "Epoch 3/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8482 - loss: 0.4859 - val_accuracy: 0.8719 - val_loss: 0.7354 - learning_rate: 4.0825e-04\n",
      "Epoch 4/10\n",
      "188/188 - 15s - 79ms/step - accuracy: 0.8597 - loss: 0.4535 - val_accuracy: 0.8975 - val_loss: 0.3684 - learning_rate: 2.0412e-04\n",
      "Epoch 5/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8652 - loss: 0.4402 - val_accuracy: 0.9040 - val_loss: 0.3223 - learning_rate: 9.1287e-05\n",
      "Epoch 6/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8663 - loss: 0.4318 - val_accuracy: 0.9043 - val_loss: 0.3160 - learning_rate: 3.7268e-05\n",
      "Epoch 7/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8668 - loss: 0.4268 - val_accuracy: 0.9048 - val_loss: 0.3142 - learning_rate: 1.4086e-05\n",
      "Epoch 8/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8672 - loss: 0.4298 - val_accuracy: 0.9050 - val_loss: 0.3133 - learning_rate: 4.9801e-06\n",
      "Epoch 9/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8698 - loss: 0.4236 - val_accuracy: 0.9051 - val_loss: 0.3132 - learning_rate: 1.6600e-06\n",
      "Epoch 10/10\n",
      "188/188 - 15s - 78ms/step - accuracy: 0.8672 - loss: 0.4253 - val_accuracy: 0.9049 - val_loss: 0.3131 - learning_rate: 5.2495e-07\n",
      "   Fold  Accuracy      Loss  Training Time (s)\n",
      "0     1  0.890500  0.356495         151.104925\n",
      "1     2  0.902250  0.313075         151.340544\n",
      "2     3  0.897083  0.339275         147.077233\n",
      "3     4  0.899250  0.332900         152.554397\n",
      "4     5  0.904917  0.313112         152.982626\n"
     ]
    }
   ],
   "source": [
    "#Now set up AdamW optimizer and run K-Fold Cross-Validation again\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# reset results for AdamW\n",
    "results = []\n",
    "# Reset the Keras session to clear previous models\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "# K-Fold Cross-Validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(f\"🔁 Fold {fold+1}/5\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(784,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Optimizer setup\n",
    "    optimizer = AdamW(\n",
    "        weight_decay=1e-4,  # Set weight decay for AdamW\n",
    "        learning_rate=1e-3,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "        )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(\n",
    "        X[train_index], y[train_index],\n",
    "        validation_data=(X[val_index], y[val_index]),\n",
    "        epochs=10,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[lr_callback],\n",
    "        verbose=2\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X[val_index], y[val_index], verbose=0)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Fold': fold + 1,\n",
    "        'Accuracy': val_accuracy,\n",
    "        'Loss': val_loss,\n",
    "        'Training Time (s)': elapsed_time\n",
    "    })\n",
    "\n",
    "# Create and display table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
